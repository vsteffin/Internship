{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f52f48",
   "metadata": {},
   "source": [
    "### 1. Python program to display header tags for wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10855c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to display header tags for wikipedia.org\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "def wikihead(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    header_tags = []\n",
    "    for i in soup.find_all('span',class_ = \"mw-headline\"):\n",
    "        header_tags.append(i.text)\n",
    "    data = pd.DataFrame({'Header Tags':header_tags})\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikihead('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf272eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3331b483",
   "metadata": {},
   "source": [
    "### 2. Python program to display IMDB's Top rated 100 movies' data(i.e. name, rating, year of release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca24aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to display IMDB's Top rated 100 movies' data(i.e. name, rating, year of release)\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def imdbtop(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    names = []\n",
    "    ratings = []\n",
    "    year_of_release = []\n",
    "    \n",
    "    \n",
    "    for i in soup.find_all('td',class_ = 'titleColumn'):\n",
    "        names.append(i.text[10:-7].replace('\\n',''))\n",
    "    for i in soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "        ratings.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('span',class_ = 'secondaryInfo'):\n",
    "        year_of_release.append(i.text[1:-1])\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    data = pd.DataFrame({'Name':names,'Rating':ratings,'Year of Release':year_of_release},index=range(1,len(names)+1)).iloc[:100]\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbtop('https://www.imdb.com/chart/top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59092c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adbb70dc",
   "metadata": {},
   "source": [
    "### 3. Python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e907c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to display IMDB's Top rated 100 Indian movies' data (i.e. name, rating, year of release).\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def imdbin(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    names = []\n",
    "    ratings = []\n",
    "    year_of_release = []\n",
    "    \n",
    "    for i in soup.find_all('td',class_ = 'titleColumn'):\n",
    "        names.append(i.text[10:-7].replace('\\n',''))\n",
    "    for i in soup.find_all('td',class_='ratingColumn imdbRating'):\n",
    "        ratings.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('span',class_ = 'secondaryInfo'):\n",
    "        year_of_release.append(i.text[1:-1])\n",
    "      \n",
    "    \n",
    "        \n",
    "    data = pd.DataFrame({'Name':names,'Rating':ratings,'Year of Release':year_of_release},index = range(1,len(names)+1)).iloc[:100]\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b21d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbin('https://www.imdb.com/india/top-rated-indian-movies/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a627c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e3ac30f",
   "metadata": {},
   "source": [
    "### 4. Python program to scrape product name, price and discounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c262aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape product name, price and discounts from meesho.com/bags-ladies\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def lbag(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    product_name = []\n",
    "    price = []\n",
    "    discount = []\n",
    "    \n",
    "    for i in soup.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 cPgaBh NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 hofZGw NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 hofZGw\"):\n",
    "        product_name.append(i.text)\n",
    "    for i in soup.find_all('h5',class_= 'Text__StyledText-sc-oo0kvp-0 dLSsNI'):\n",
    "        price.append(i.text.replace('₹',''))\n",
    "    for i in soup.find_all('span',class_ = 'Text__StyledText-sc-oo0kvp-0 cZvGTZ'):\n",
    "        discount.append(i.text)\n",
    "        \n",
    "    data = pd.DataFrame({'Product Name': product_name,'Price(₹)': price,'Discount': discount})\n",
    "    return data\n",
    "    print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbag('https://meesho.com/bags-ladies/pl/p7vbp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b80655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "489788cd",
   "metadata": {},
   "source": [
    "### 5. Python program to scrape cricket rankings from icc-cricket.com(Men's Cricket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862ab14",
   "metadata": {},
   "source": [
    "#### a.Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe2b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def icc_men_team(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    team = []\n",
    "    matches = []\n",
    "    points = []\n",
    "    rating = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in soup.find_all('span',class_ = 'u-hide-phablet'):\n",
    "            team.append(i.text)\n",
    "    team = team[:20]\n",
    "    \n",
    "    for x in soup.find_all('td', class_='rankings-block__banner--matches'):\n",
    "        matches.append(x.text)\n",
    "    for y in soup.find_all('td',class_='rankings-block__banner--points'):\n",
    "        points.append(y.text)\n",
    "    for z in soup.find_all('td',class_='rankings-block__banner--rating u-text-right'):\n",
    "        rating.append(z.text.replace('\\n','').replace(' ',''))\n",
    "\n",
    "    a = []\n",
    "    for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "        b = []\n",
    "        c = []\n",
    "        a.append(i.text)\n",
    "        for e in range(len(a)):\n",
    "            if e%2 != 0:\n",
    "                b.append(a[e])\n",
    "            else:\n",
    "                c.append(a[e])\n",
    "            e = e+1\n",
    "    for n in c:\n",
    "        matches.append(n)\n",
    "    for m in b:\n",
    "        points.append(m)  \n",
    "\n",
    "    for a in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "        rating.append(a.text)\n",
    "\n",
    "    data = pd.DataFrame({\"Team\":team,\"Matches\":matches,\"Points\":points,\"Rating\":rating}, index = range(1,len(matches)+1)).iloc[:10]\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_men_team('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d8f51d",
   "metadata": {},
   "source": [
    "#### b. Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d44602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def icc_men_bat(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    player = []\n",
    "    team = []\n",
    "    rating = []\n",
    "    \n",
    "    for i in soup.find_all('div', class_='rankings-block__banner--name-large'):\n",
    "        player.append(i.text)\n",
    "    for t in soup.find_all('div',class_= 'rankings-block__banner--nationality'):\n",
    "        team.append(t.text.replace('\\n','').replace(' ',''))\n",
    "    for i in soup.find_all('div',class_ = 'rankings-block__banner--rating'):\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "    for i in soup.find_all('td',class_= 'table-body__cell rankings-table__name name'):\n",
    "        player.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('span',class_='table-body__logo-text'):\n",
    "        team.append(i.text)\n",
    "    for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "    data = pd.DataFrame({'Player':player,'Team':team, 'Rating':rating}, index = range(1,len(player)+1)).iloc[:10]\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_men_bat('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b645d",
   "metadata": {},
   "source": [
    "#### c. Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e891769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape top 10 ODI bowlers along with the records of their team and rating\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def icc_men_bowl(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    player = []\n",
    "    team = []\n",
    "    rating = []\n",
    "    \n",
    "    for i in soup.find_all('div', class_='rankings-block__banner--name-large'):\n",
    "        player.append(i.text)\n",
    "    for t in soup.find_all('div',class_= 'rankings-block__banner--nationality'):\n",
    "        team.append(t.text.replace('\\n','').replace(' ',''))\n",
    "    for i in soup.find_all('div',class_ = 'rankings-block__banner--rating'):\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "    for i in soup.find_all('td',class_= 'table-body__cell rankings-table__name name'):\n",
    "        player.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('span',class_='table-body__logo-text'):\n",
    "        team.append(i.text)\n",
    "    for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "    data = pd.DataFrame({'Player':player,'Team':team, 'Rating':rating}, index = range(1,len(player)+1)).iloc[:10]\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_men_bowl('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac034f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48cf8853",
   "metadata": {},
   "source": [
    "### 6. Python program to scrape cricket rankings from icc-cricket.com."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09065ffb",
   "metadata": {},
   "source": [
    "#### a. Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba860e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def icc_women_team(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    team = []\n",
    "    matches = []\n",
    "    points = []\n",
    "    rating = []\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in soup.find_all('span',class_ = 'u-hide-phablet'):\n",
    "            team.append(i.text)\n",
    "            team = team[:11]\n",
    "    \n",
    "    for x in soup.find_all('td', class_='rankings-block__banner--matches'):\n",
    "        matches.append(x.text)\n",
    "    for y in soup.find_all('td',class_='rankings-block__banner--points'):\n",
    "        points.append(y.text)\n",
    "    for z in soup.find_all('td',class_='rankings-block__banner--rating u-text-right'):\n",
    "        rating.append(z.text.replace('\\n','').replace(' ',''))\n",
    "\n",
    "    a = []\n",
    "    for i in soup.find_all('td',class_='table-body__cell u-center-text'):\n",
    "        b = []\n",
    "        c = []\n",
    "        a.append(i.text)\n",
    "        for e in range(len(a)):\n",
    "            if e%2 != 0:\n",
    "                b.append(a[e])\n",
    "            else:\n",
    "                c.append(a[e])\n",
    "            e = e+1\n",
    "    for n in c:\n",
    "        matches.append(n)\n",
    "    for m in b:\n",
    "        points.append(m)  \n",
    "\n",
    "    for a in soup.find_all('td',class_='table-body__cell u-text-right rating'):\n",
    "        rating.append(a.text)\n",
    "        \n",
    "    data = pd.DataFrame({\"Team\":team,\"Matches\":matches,\"Points\":points,\"Rating\":rating}, index = range(1,len(matches)+1)).iloc[:10]\n",
    "    return data\n",
    "    print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_women_team('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5700740",
   "metadata": {},
   "source": [
    "#### b. Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def icc_women_bat(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    player = []\n",
    "    team = []\n",
    "    rating = []\n",
    "    \n",
    "    for i in soup.find_all('div', class_='rankings-block__banner--name-large'):\n",
    "        player.append(i.text)\n",
    "    for t in soup.find_all('div',class_= 'rankings-block__banner--nationality'):\n",
    "        team.append(t.text.replace('\\n','').replace(' ',''))\n",
    "    for i in soup.find_all('div',class_ = 'rankings-block__banner--rating'):\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "    for i in soup.find_all('td',class_= 'table-body__cell rankings-table__name name'):\n",
    "        player.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('span',class_='table-body__logo-text'):\n",
    "        team.append(i.text)\n",
    "    for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "    data = pd.DataFrame({'Player':player,'Team':team, 'Rating':rating}, index = range(1,len(player)+1)).iloc[:10]\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf62e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_women_bat('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0094c6b",
   "metadata": {},
   "source": [
    "#### c. Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56436998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def icc_women_all(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    player = []\n",
    "    team = []\n",
    "    rating = []\n",
    "    \n",
    "    for i in soup.find_all('div', class_='rankings-block__banner--name-large'):\n",
    "        player.append(i.text)\n",
    "    for t in soup.find_all('div',class_= 'rankings-block__banner--nationality'):\n",
    "        team.append(t.text.replace('\\n','').replace(' ',''))\n",
    "    for i in soup.find_all('div',class_ = 'rankings-block__banner--rating'):\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "    for i in soup.find_all('td',class_= 'table-body__cell rankings-table__name name'):\n",
    "        player.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('span',class_='table-body__logo-text'):\n",
    "        team.append(i.text)\n",
    "    for i in soup.find_all('td',class_='table-body__cell rating'):\n",
    "        rating.append(i.text)\n",
    "        \n",
    "        \n",
    "    data = pd.DataFrame({'Player':player,'Team':team, 'Rating':rating}, index = range(1,len(player)+1)).iloc[:10]\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_women_all('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648b22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5923c680",
   "metadata": {},
   "source": [
    "### 7. Python program to scrape details of all the posts from coreyms.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape details of all the posts from coreyms.com.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def coreyms(url):\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    heading = []\n",
    "    date = []\n",
    "    content = []\n",
    "    code = []\n",
    "    \n",
    "    for i in soup.find_all('h2',class_='entry-title'):\n",
    "        heading.append(i.text)\n",
    "    for i in soup.find_all('time',class_='entry-time'):\n",
    "        date.append(i.text)\n",
    "    for i in soup.find_all('div',class_='entry-content'):\n",
    "        content.append(i.text.replace('\\n',''))\n",
    "    for co in soup.find_all(\"iframe\", class_=\"youtube-player\"):\n",
    "        code.append(co['src'])\n",
    "    code.insert(4,'NaN')\n",
    "    \n",
    "    data = pd.DataFrame({'Heading':heading,'Date':date,'Content':content,'Code for Video':code})\n",
    "    \n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "coreyms('https://coreyms.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc6e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88703b16",
   "metadata": {},
   "source": [
    "### 8. Python program to scrape house details from nobroker.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefca437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape house details from nobroker.in including house title, location, area, EMI and price. Indira Nagar, Jayanagar, Rajaji Nagar\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def house(url):\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    title = []\n",
    "    location = []\n",
    "    area = []\n",
    "    EMI = []\n",
    "    price = []\n",
    "    \n",
    "    for head in soup.find_all('span',class_='overflow-hidden overflow-ellipsis whitespace-nowrap max-w-80pe po:max-w-full'):\n",
    "        title.append(head.text)\n",
    "        \n",
    "    for loc in soup.find_all('div', class_= 'mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95'):\n",
    "        location.append(loc.text)\n",
    "        \n",
    "    ar =[]\n",
    "    for i in soup.find_all('div',class_='font-semi-bold heading-6'):\n",
    "        ar.append(i.text)\n",
    "    area = list(ar[x] for x in range(0,len(ar),3))\n",
    "    \n",
    "    a = []\n",
    "    for emi in soup.find_all('div',class_='font-semi-bold heading-6'):\n",
    "        a.append(emi.text)\n",
    "    EMI = list(a[x] for x in range(1,len(a),3))\n",
    "\n",
    "    \n",
    "    pr = []\n",
    "    for p in soup.find_all('div',class_='font-semi-bold heading-6'):\n",
    "        pr.append(p.text)\n",
    "    price = list(pr[x] for x in range(2,len(pr),3))\n",
    "\n",
    "    \n",
    "    data = pd.DataFrame({'House Title': title,'Location':location,'Area':area,'EMI':EMI,'Price':price})\n",
    "    return data\n",
    "    print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e356e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "house('https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45NzgzNjkyLCJsb24iOjc3LjY0MDgzNTYsInBsYWNlSWQiOiJDaElKa1FOM0dLUVdyanNSTmhCUUpyaEdEN1UiLCJwbGFjZU5hbWUiOiJJbmRpcmFuYWdhciJ9LHsibGF0IjoxMi45MzA3NzM1LCJsb24iOjc3LjU4MzgzMDIsInBsYWNlSWQiOiJDaElKMmRkbFo1Z1ZyanNSaDFCT0FhZi1vcnMiLCJwbGFjZU5hbWUiOiJKYXlhbmFnYXIifSx7ImxhdCI6MTIuOTk4MTczMiwibG9uIjo3Ny41NTMwNDQ1OTk5OTk5OSwicGxhY2VJZCI6IkNoSUp4Zlc0RFBNOXJqc1JLc05URy01cF9RUSIsInBsYWNlTmFtZSI6IlJhamFqaW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Indiranagar,&locality=Jayanagar,&locality=Rajajinagar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f2e72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bee3a3a3",
   "metadata": {},
   "source": [
    "### 9. Python program to scrape mentioned details from dineout.co.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d594c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to scrape mentioned details from dineout.co.in\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def restaurant(url):\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    restaurant_name = []\n",
    "    cuisine = []\n",
    "    location = []\n",
    "    ratings = []\n",
    "    image = []\n",
    "    \n",
    "    for res in soup.find_all('a',class_ = 'restnt-name ellipsis'):\n",
    "        restaurant_name.append(res.text)\n",
    "\n",
    "\n",
    "    for loc in soup.find_all('div', class_ = 'restnt-loc ellipsis'):\n",
    "        location.append(loc.text)\n",
    "\n",
    "    c = []    \n",
    "    for cus in soup.find_all('span',class_ = 'double-line-ellipsis'):\n",
    "        c.append(cus.text.replace('|',''))\n",
    "    cuisine = list(c[x][22:] for x in range(0,len(c)))\n",
    "\n",
    "    for r in soup.find_all('div',class_= 'restnt-rating rating-4'):\n",
    "        ratings.append(r.text)\n",
    "\n",
    "    for img in soup.find_all('img',class_='no-img'):\n",
    "        image.append(img['data-src'])\n",
    "\n",
    "    data = pd.DataFrame({'Restaurant Name':restaurant_name,'Cuisine':cuisine,'Location':location,'Rating':ratings,'Image URL':image})\n",
    "    return data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant('https://www.dineout.co.in/delhi-restaurants/buffet-special')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6336d1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "078bdbd8",
   "metadata": {},
   "source": [
    "### 10. Python program to scrape first 10 product details which include product name , price , Image URL from bewakoof.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape first 10 product details which include product name, price, image URL from bewakoof.com\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def bewa(url):\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "    \n",
    "    product_name = []\n",
    "    price = []\n",
    "    image = []\n",
    "    \n",
    "    for pn in soup.find_all('h3'):\n",
    "        product_name.append(pn.text)\n",
    "        product_name = product_name[:10]\n",
    "        \n",
    "    for pr in soup.find_all('div', class_='productPriceBox clearfix'):\n",
    "        price.append(pr.text[:5].replace('₹ ',''))\n",
    "        price = price[:10]\n",
    "\n",
    "    for img in soup.find_all('img',class_='productImgTag'):\n",
    "        image.append(img['src'])\n",
    "        image = image[:10]\n",
    "        \n",
    "    data = pd.DataFrame({'Product Name':product_name, 'Price':price,'Image URL':image}, index = range(1,len(image)+1))\n",
    "    return data\n",
    "    print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bewa('https://www.bewakoof.com/women-t-shirts?ga_q=tshirts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec7b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
